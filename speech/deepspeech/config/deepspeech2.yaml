speech_config:
  sample_rate: 16000
  frame_ms: 25
  stride_ms: 10
  num_feature_bins: 80
  feature_type: log_mel_spectrogram
  preemphasis: 0.97
  pad_end: False
  lower_edge_hertz: 0.0
  upper_edge_hertz: 8000.0
  output_floor: 1e-9
  log_base: "10"
  nfft: 512
  normalize_signal: True
  normalize_zscore: True
  normalize_min_max: False
  padding: 0.0

decoder_config:
  blank_index: 0
  beam_width: 0
  norm_score: True
  lm_config: null
  normalization_form: NFKC
  # unknown_token: "<unk>"
  # unknown_index: -1
  # pad_token: "<pad>"
  # pad_index: 2
  # bos_token: "<bos>"
  # bos_index: 1
  # eos_token: "<eos>"
  # eos_index: 3
  vocabulary: /home/hemanth/GIT_Projects/Paper-Implementations/speech/deepspeech/vocabularies/english.characters

model_config:
  name: deepspeech2
  conv_type: conv2d
  conv_kernels: [ [ 11, 41 ], [ 11, 21 ] ]
  conv_strides: [[ 2, 2 ], [ 1, 2 ] ]
  conv_filters: [ 32, 32 ]
  conv_activation: relu
  conv_dropout: 0.2
  conv_padding: same
  rnn_nlayers: 5
  rnn_type: lstm
  rnn_units: 512
  rnn_bidirectional: False
  rnn_unroll: False
  rnn_rowconv: 5
  rnn_rowconv_activation: relu
  rnn_dropout: 0.3
  fc_nlayers: 1
  fc_units: 1024
  fc_activation: relu
  fc_dropout: 0.3
  blank: 0
  vocab_size: 29
  kernel_regularizer:
    class_name: l2
    config:
      l2: 0.001
  bias_regularizer:
    class_name: l2
    config:
      l2: 0.001
  kernel_initializer:
    class_name: glorot_uniform
    config:
      seed: 42
  bias_initializer: zeros

data_config:
  train_dataset_config:
    enabled: True
    sample_rate: 16000
    data_paths:
      - /home/hemanth/GIT_Projects/Paper-Implementations/speech/data/LibriSpeech/train_860.tsv
    shuffle: True
    cache: False
    buffer_size: 1000
    drop_remainder: True
    stage: train
    metadata: null
    indefinite: True

  eval_dataset_config:
    enabled: True
    sample_rate: 16000
    data_paths:
      - /home/hemanth/GIT_Projects/Paper-Implementations/speech/data/LibriSpeech/val.tsv
    shuffle: True
    cache: False
    buffer_size: 1000
    drop_remainder: True
    stage: eval
    metadata: null
    indefinite: True

  test_dataset_configs:
    enabled: True
    sample_rate: 16000
    data_paths:
      - /home/hemanth/GIT_Projects/Paper-Implementations/speech/data/LibriSpeech/test_orig.tsv
    shuffle: False
    cache: False
    buffer_size: null
    drop_remainder: False
    stage: test
    indefinite: False

learning_config:
  optimizer_config:
    class_name: Adam
    config:
      learning_rate: 1e-4
        # class_name: src.optimizers.schedulers>TransformerScheduler
        # config:
        #   d_model: 256
        #   warmup_steps: 8192
        #   max_lr: 1e-3
        #   min_lr: 1e-6
      beta_1: 0.9
      beta_2: 0.98
      epsilon: 1e-9
      clipnorm: 1.0
      
  pretrained: False

  running_config:
    batch_size: 4
    num_epochs: 200
    dataset_type: slice
    devices: [0]
    checkpoint:
      filepath: checkpoints/{epoch:02d}.h5
      save_best_only: False
      save_weights_only: True
      save_freq: epoch
    states_dir: states
    csv_logger: training.log
    tensorboard:
      log_dir: tensorboard
      histogram_freq: 1
      write_graph: True
      write_images: True
      update_freq: epoch
      profile_batch: 2
