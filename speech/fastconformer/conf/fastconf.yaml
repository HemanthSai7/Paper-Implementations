speech_config:
  sample_rate: 16000
  frame_ms: 25
  stride_ms: 10
  num_feature_bins: 80
  feature_type: log_mel_spectrogram
  preemphasis: 0.97
  pad_end: False
  lower_edge_hertz: 0.0
  upper_edge_hertz: 8000.0
  output_floor: 1e-9
  log_base: "10"
  nfft: 512
  normalize_signal: True
  normalize_zscore: False
  normalize_min_max: False
  padding: 0.0

decoder_config:
  vocabulary: ../../../../vocabularies/english.characters
  blank_at_zero: True
  beam_width: 0
  norm_score: True

model_config:
  name: fastconformer
  d_model: 256
  encoder_subsampling:
    name: conv1d
    kernel_size: [9,9,9]
    strides: [2,2,2]
    padding: ["valid", "valid", "valid"]
    activation: ["gelu", "gelu", "gelu"]
  encoder_num_blocks: 8
  encoder_head_size: 32
  encoder_num_heads: 16
  encoder_mha_type: relmha
  encoder_kernel_size: 32
  encoder_fc_factor: 0.5
  encoder_dropout: 0.1
  prediction_embed_dim: 320
  prediction_embed_dropout: 0
  prediction_num_rnns: 1
  prediction_rnn_units: 320
  prediction_rnn_type: lstm
  prediction_rnn_implementation: 2
  prediction_layer_norm: True
  prediction_projection_units: 0
  joint_dim: 320
  prejoint_linear: True
  joint_activation: tanh
  joint_mode: add
  kernel_regularizer:
    class_name: l2
    config:
      l2: 0.0001
  bias_regularizer:
    class_name: l2
    config:
      l2: 0.0001
  kernel_initializer:
    class_name: glorot_uniform
    config:
      seed: 42
  bias_initializer: zeros

data_config:
  train_dataset_config:
    enabled: True
    data_paths:
      - ../../../LibriSpeech/train.tsv
    shuffle: True
    cache: True
    buffer_size: 100
    drop_remainder: True
    stage: train
    indefinite: True

  eval_dataset_config:
    enabled: True
    data_paths:
      - ../../../LibriSpeech/val.tsv
    shuffle: False
    cache: True
    buffer_size: 100
    drop_remainder: True
    stage: eval
    indefinite: True

  test_dataset_config:
    enabled: True
    data_paths:
      - ../../../LibriSpeech/test.tsv
    shuffle: False
    cache: True
    buffer_size: 100
    drop_remainder: True
    stage: test
    indefinite: False

learning_config:
  optimizer_config:
    class_name: Adam
    config:
      learning_rate:
        class_name: src.optimizers.schedules>TransformerLearningRateSchedule
        config:
          d_model: 256
          warmup_steps: 8192
          max_lr: null
          min_lr: null
      beta_1: 0.9
      beta_2: 0.98
      epsilon: 1e-9

  pretrained: False

  running_config:
    batch_size: 4
    num_epochs: 200
    pretrained: False
    devices: [0]
    checkpoint:
      filepath: checkpoints/{epoch:02d}.h5
      save_best_only: False
      save_weights_only: True
      save_freq: epoch
    states_dir: states
    csv_logger: training.log
    tensorboard:
      log_dir: tensorboard
      histogram_freq: 1
      write_graph: True
      write_images: True
      update_freq: epoch
      profile_batch: 2